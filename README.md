# ImageDetection

This project is detecting obbussive images for children.
The algorithm searches in images:
    1. porn, nudity or other human inappropriate content.
    2. drugs including weed plants.
    3. weapons, such as knifes and guns
The object recognition was made by training an image recogrition model, using a self build dataset of (train and test) images and annotations. 
Writen by Yocheved N. and Hila S.
